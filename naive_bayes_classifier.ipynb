{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting scikit-learn\n",
      "  Obtaining dependency information for scikit-learn from https://files.pythonhosted.org/packages/f6/28/b569523552a11b49dc4d33952f43dedb23792fe8ce2f2151d070d615861a/scikit_learn-1.4.0-1-cp312-cp312-win_amd64.whl.metadata\n",
      "  Downloading scikit_learn-1.4.0-1-cp312-cp312-win_amd64.whl.metadata (11 kB)\n",
      "Requirement already satisfied: numpy<2.0,>=1.19.5 in c:\\users\\александр алейник\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from scikit-learn) (1.26.3)\n",
      "Collecting scipy>=1.6.0 (from scikit-learn)\n",
      "  Obtaining dependency information for scipy>=1.6.0 from https://files.pythonhosted.org/packages/f3/31/91a2a3c5eb85d2bfa86d7c98f2df5d77dcdefb3d80ca9f9037ad04393acf/scipy-1.12.0-cp312-cp312-win_amd64.whl.metadata\n",
      "  Downloading scipy-1.12.0-cp312-cp312-win_amd64.whl.metadata (60 kB)\n",
      "     ---------------------------------------- 0.0/60.4 kB ? eta -:--:--\n",
      "     ------ --------------------------------- 10.2/60.4 kB ? eta -:--:--\n",
      "     ------------------- ------------------ 30.7/60.4 kB 435.7 kB/s eta 0:00:01\n",
      "     ------------------- ------------------ 30.7/60.4 kB 435.7 kB/s eta 0:00:01\n",
      "     -------------------------------- ----- 51.2/60.4 kB 262.6 kB/s eta 0:00:01\n",
      "     -------------------------------------- 60.4/60.4 kB 321.8 kB/s eta 0:00:00\n",
      "Collecting joblib>=1.2.0 (from scikit-learn)\n",
      "  Obtaining dependency information for joblib>=1.2.0 from https://files.pythonhosted.org/packages/10/40/d551139c85db202f1f384ba8bcf96aca2f329440a844f924c8a0040b6d02/joblib-1.3.2-py3-none-any.whl.metadata\n",
      "  Downloading joblib-1.3.2-py3-none-any.whl.metadata (5.4 kB)\n",
      "Collecting threadpoolctl>=2.0.0 (from scikit-learn)\n",
      "  Obtaining dependency information for threadpoolctl>=2.0.0 from https://files.pythonhosted.org/packages/81/12/fd4dea011af9d69e1cad05c75f3f7202cdcbeac9b712eea58ca779a72865/threadpoolctl-3.2.0-py3-none-any.whl.metadata\n",
      "  Downloading threadpoolctl-3.2.0-py3-none-any.whl.metadata (10.0 kB)\n",
      "Downloading scikit_learn-1.4.0-1-cp312-cp312-win_amd64.whl (10.6 MB)\n",
      "   ---------------------------------------- 0.0/10.6 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/10.6 MB 960.0 kB/s eta 0:00:11\n",
      "    --------------------------------------- 0.1/10.6 MB 1.7 MB/s eta 0:00:07\n",
      "   - -------------------------------------- 0.3/10.6 MB 2.4 MB/s eta 0:00:05\n",
      "   -- ------------------------------------- 0.6/10.6 MB 3.2 MB/s eta 0:00:04\n",
      "   ---- ----------------------------------- 1.1/10.6 MB 5.1 MB/s eta 0:00:02\n",
      "   ------ --------------------------------- 1.8/10.6 MB 6.7 MB/s eta 0:00:02\n",
      "   -------- ------------------------------- 2.3/10.6 MB 7.3 MB/s eta 0:00:02\n",
      "   ----------- ---------------------------- 2.9/10.6 MB 8.2 MB/s eta 0:00:01\n",
      "   --------------- ------------------------ 4.1/10.6 MB 10.1 MB/s eta 0:00:01\n",
      "   ----------------- ---------------------- 4.7/10.6 MB 10.3 MB/s eta 0:00:01\n",
      "   --------------------- ------------------ 5.6/10.6 MB 11.1 MB/s eta 0:00:01\n",
      "   ----------------------- ---------------- 6.2/10.6 MB 11.3 MB/s eta 0:00:01\n",
      "   ------------------------- -------------- 6.8/10.6 MB 11.5 MB/s eta 0:00:01\n",
      "   ---------------------------- ----------- 7.6/10.6 MB 11.8 MB/s eta 0:00:01\n",
      "   ------------------------------ --------- 8.0/10.6 MB 12.2 MB/s eta 0:00:01\n",
      "   ------------------------------ --------- 8.0/10.6 MB 12.2 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 9.2/10.6 MB 11.7 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 10.1/10.6 MB 12.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------  10.6/10.6 MB 14.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 10.6/10.6 MB 13.9 MB/s eta 0:00:00\n",
      "Downloading joblib-1.3.2-py3-none-any.whl (302 kB)\n",
      "   ---------------------------------------- 0.0/302.2 kB ? eta -:--:--\n",
      "   ---------------------------------------- 302.2/302.2 kB 9.4 MB/s eta 0:00:00\n",
      "Downloading scipy-1.12.0-cp312-cp312-win_amd64.whl (45.8 MB)\n",
      "   ---------------------------------------- 0.0/45.8 MB ? eta -:--:--\n",
      "    --------------------------------------- 0.9/45.8 MB 20.3 MB/s eta 0:00:03\n",
      "   - -------------------------------------- 1.7/45.8 MB 18.6 MB/s eta 0:00:03\n",
      "   -- ------------------------------------- 2.8/45.8 MB 20.3 MB/s eta 0:00:03\n",
      "   -- ------------------------------------- 3.4/45.8 MB 18.2 MB/s eta 0:00:03\n",
      "   --- ------------------------------------ 4.0/45.8 MB 18.2 MB/s eta 0:00:03\n",
      "   --- ------------------------------------ 4.0/45.8 MB 15.0 MB/s eta 0:00:03\n",
      "   --- ------------------------------------ 4.0/45.8 MB 15.0 MB/s eta 0:00:03\n",
      "   ---- ----------------------------------- 4.8/45.8 MB 12.6 MB/s eta 0:00:04\n",
      "   ---- ----------------------------------- 5.0/45.8 MB 12.0 MB/s eta 0:00:04\n",
      "   ---- ----------------------------------- 5.4/45.8 MB 11.8 MB/s eta 0:00:04\n",
      "   ---- ----------------------------------- 5.7/45.8 MB 11.0 MB/s eta 0:00:04\n",
      "   ----- ---------------------------------- 5.8/45.8 MB 10.7 MB/s eta 0:00:04\n",
      "   ----- ---------------------------------- 5.8/45.8 MB 10.7 MB/s eta 0:00:04\n",
      "   ----- ---------------------------------- 6.3/45.8 MB 10.0 MB/s eta 0:00:04\n",
      "   ----- ---------------------------------- 6.8/45.8 MB 9.6 MB/s eta 0:00:05\n",
      "   ----- ---------------------------------- 6.8/45.8 MB 9.7 MB/s eta 0:00:05\n",
      "   ----- ---------------------------------- 6.8/45.8 MB 8.9 MB/s eta 0:00:05\n",
      "   ------ --------------------------------- 7.2/45.8 MB 8.5 MB/s eta 0:00:05\n",
      "   ------ --------------------------------- 7.3/45.8 MB 8.2 MB/s eta 0:00:05\n",
      "   ------ --------------------------------- 7.6/45.8 MB 8.3 MB/s eta 0:00:05\n",
      "   ------ --------------------------------- 7.7/45.8 MB 8.3 MB/s eta 0:00:05\n",
      "   ------- -------------------------------- 8.3/45.8 MB 8.2 MB/s eta 0:00:05\n",
      "   ------- -------------------------------- 8.5/45.8 MB 8.0 MB/s eta 0:00:05\n",
      "   ------- -------------------------------- 8.7/45.8 MB 7.8 MB/s eta 0:00:05\n",
      "   ------- -------------------------------- 8.9/45.8 MB 7.7 MB/s eta 0:00:05\n",
      "   -------- ------------------------------- 9.2/45.8 MB 7.8 MB/s eta 0:00:05\n",
      "   -------- ------------------------------- 9.4/45.8 MB 7.6 MB/s eta 0:00:05\n",
      "   -------- ------------------------------- 9.4/45.8 MB 7.6 MB/s eta 0:00:05\n",
      "   -------- ------------------------------- 9.6/45.8 MB 7.2 MB/s eta 0:00:06\n",
      "   -------- ------------------------------- 9.7/45.8 MB 7.0 MB/s eta 0:00:06\n",
      "   -------- ------------------------------- 9.8/45.8 MB 6.9 MB/s eta 0:00:06\n",
      "   -------- ------------------------------- 10.0/45.8 MB 6.7 MB/s eta 0:00:06\n",
      "   -------- ------------------------------- 10.0/45.8 MB 6.6 MB/s eta 0:00:06\n",
      "   -------- ------------------------------- 10.2/45.8 MB 6.4 MB/s eta 0:00:06\n",
      "   -------- ------------------------------- 10.3/45.8 MB 6.3 MB/s eta 0:00:06\n",
      "   --------- ------------------------------ 10.4/45.8 MB 6.1 MB/s eta 0:00:06\n",
      "   --------- ------------------------------ 10.6/45.8 MB 6.0 MB/s eta 0:00:06\n",
      "   --------- ------------------------------ 10.8/45.8 MB 5.8 MB/s eta 0:00:06\n",
      "   --------- ------------------------------ 11.0/45.8 MB 5.7 MB/s eta 0:00:07\n",
      "   ---------- ----------------------------- 11.5/45.8 MB 5.7 MB/s eta 0:00:07\n",
      "   ---------- ----------------------------- 12.1/45.8 MB 5.6 MB/s eta 0:00:06\n",
      "   ----------- ---------------------------- 12.7/45.8 MB 5.5 MB/s eta 0:00:06\n",
      "   ----------- ---------------------------- 13.2/45.8 MB 5.5 MB/s eta 0:00:06\n",
      "   ----------- ---------------------------- 13.7/45.8 MB 5.5 MB/s eta 0:00:06\n",
      "   ------------ --------------------------- 14.3/45.8 MB 5.8 MB/s eta 0:00:06\n",
      "   ------------ --------------------------- 14.8/45.8 MB 5.7 MB/s eta 0:00:06\n",
      "   ------------- -------------------------- 15.2/45.8 MB 5.7 MB/s eta 0:00:06\n",
      "   ------------- -------------------------- 15.2/45.8 MB 5.7 MB/s eta 0:00:06\n",
      "   ------------- -------------------------- 15.4/45.8 MB 5.6 MB/s eta 0:00:06\n",
      "   ------------- -------------------------- 15.6/45.8 MB 5.5 MB/s eta 0:00:06\n",
      "   ------------- -------------------------- 15.8/45.8 MB 5.5 MB/s eta 0:00:06\n",
      "   ------------- -------------------------- 16.0/45.8 MB 5.5 MB/s eta 0:00:06\n",
      "   -------------- ------------------------- 16.2/45.8 MB 5.5 MB/s eta 0:00:06\n",
      "   -------------- ------------------------- 16.4/45.8 MB 5.4 MB/s eta 0:00:06\n",
      "   -------------- ------------------------- 16.7/45.8 MB 5.4 MB/s eta 0:00:06\n",
      "   -------------- ------------------------- 17.0/45.8 MB 5.4 MB/s eta 0:00:06\n",
      "   --------------- ------------------------ 17.3/45.8 MB 5.6 MB/s eta 0:00:06\n",
      "   --------------- ------------------------ 17.6/45.8 MB 5.7 MB/s eta 0:00:05\n",
      "   --------------- ------------------------ 17.9/45.8 MB 5.6 MB/s eta 0:00:05\n",
      "   --------------- ------------------------ 18.2/45.8 MB 5.7 MB/s eta 0:00:05\n",
      "   ---------------- ----------------------- 18.5/45.8 MB 5.6 MB/s eta 0:00:05\n",
      "   ---------------- ----------------------- 18.8/45.8 MB 5.7 MB/s eta 0:00:05\n",
      "   ---------------- ----------------------- 19.1/45.8 MB 5.8 MB/s eta 0:00:05\n",
      "   ---------------- ----------------------- 19.4/45.8 MB 5.7 MB/s eta 0:00:05\n",
      "   ----------------- ---------------------- 19.7/45.8 MB 6.1 MB/s eta 0:00:05\n",
      "   ----------------- ---------------------- 20.0/45.8 MB 6.4 MB/s eta 0:00:05\n",
      "   ----------------- ---------------------- 20.4/45.8 MB 6.6 MB/s eta 0:00:04\n",
      "   ----------------- ---------------------- 20.4/45.8 MB 6.7 MB/s eta 0:00:04\n",
      "   ----------------- ---------------------- 20.4/45.8 MB 6.4 MB/s eta 0:00:04\n",
      "   ------------------ --------------------- 20.7/45.8 MB 6.6 MB/s eta 0:00:04\n",
      "   ------------------ --------------------- 20.8/45.8 MB 6.5 MB/s eta 0:00:04\n",
      "   ------------------ --------------------- 21.2/45.8 MB 6.6 MB/s eta 0:00:04\n",
      "   ------------------ --------------------- 21.5/45.8 MB 6.6 MB/s eta 0:00:04\n",
      "   ------------------- -------------------- 21.8/45.8 MB 6.5 MB/s eta 0:00:04\n",
      "   ------------------- -------------------- 22.1/45.8 MB 6.4 MB/s eta 0:00:04\n",
      "   ------------------- -------------------- 22.4/45.8 MB 6.4 MB/s eta 0:00:04\n",
      "   ------------------- -------------------- 22.7/45.8 MB 6.2 MB/s eta 0:00:04\n",
      "   -------------------- ------------------- 23.0/45.8 MB 6.2 MB/s eta 0:00:04\n",
      "   -------------------- ------------------- 23.3/45.8 MB 6.1 MB/s eta 0:00:04\n",
      "   -------------------- ------------------- 23.6/45.8 MB 6.0 MB/s eta 0:00:04\n",
      "   -------------------- ------------------- 24.0/45.8 MB 6.0 MB/s eta 0:00:04\n",
      "   --------------------- ------------------ 24.3/45.8 MB 5.9 MB/s eta 0:00:04\n",
      "   --------------------- ------------------ 24.6/45.8 MB 5.8 MB/s eta 0:00:04\n",
      "   --------------------- ------------------ 24.9/45.8 MB 5.8 MB/s eta 0:00:04\n",
      "   --------------------- ------------------ 25.2/45.8 MB 5.7 MB/s eta 0:00:04\n",
      "   ---------------------- ----------------- 25.5/45.8 MB 5.9 MB/s eta 0:00:04\n",
      "   ---------------------- ----------------- 25.8/45.8 MB 5.9 MB/s eta 0:00:04\n",
      "   ---------------------- ----------------- 26.1/45.8 MB 6.0 MB/s eta 0:00:04\n",
      "   ----------------------- ---------------- 26.4/45.8 MB 6.1 MB/s eta 0:00:04\n",
      "   ----------------------- ---------------- 26.7/45.8 MB 6.2 MB/s eta 0:00:04\n",
      "   ----------------------- ---------------- 27.0/45.8 MB 6.2 MB/s eta 0:00:04\n",
      "   ----------------------- ---------------- 27.3/45.8 MB 6.2 MB/s eta 0:00:03\n",
      "   ------------------------ --------------- 27.6/45.8 MB 6.2 MB/s eta 0:00:03\n",
      "   ------------------------ --------------- 27.9/45.8 MB 6.2 MB/s eta 0:00:03\n",
      "   ------------------------ --------------- 28.2/45.8 MB 6.2 MB/s eta 0:00:03\n",
      "   ------------------------ --------------- 28.5/45.8 MB 6.2 MB/s eta 0:00:03\n",
      "   ------------------------- -------------- 28.9/45.8 MB 6.2 MB/s eta 0:00:03\n",
      "   ------------------------- -------------- 29.2/45.8 MB 6.2 MB/s eta 0:00:03\n",
      "   ------------------------- -------------- 29.5/45.8 MB 6.2 MB/s eta 0:00:03\n",
      "   ------------------------- -------------- 29.8/45.8 MB 6.2 MB/s eta 0:00:03\n",
      "   -------------------------- ------------- 30.1/45.8 MB 6.2 MB/s eta 0:00:03\n",
      "   -------------------------- ------------- 30.4/45.8 MB 6.2 MB/s eta 0:00:03\n",
      "   -------------------------- ------------- 30.4/45.8 MB 6.2 MB/s eta 0:00:03\n",
      "   -------------------------- ------------- 30.5/45.8 MB 6.0 MB/s eta 0:00:03\n",
      "   --------------------------- ------------ 31.1/45.8 MB 6.6 MB/s eta 0:00:03\n",
      "   --------------------------- ------------ 31.3/45.8 MB 6.5 MB/s eta 0:00:03\n",
      "   --------------------------- ------------ 31.5/45.8 MB 6.5 MB/s eta 0:00:03\n",
      "   --------------------------- ------------ 31.8/45.8 MB 6.4 MB/s eta 0:00:03\n",
      "   --------------------------- ------------ 32.0/45.8 MB 6.4 MB/s eta 0:00:03\n",
      "   ---------------------------- ----------- 32.2/45.8 MB 6.3 MB/s eta 0:00:03\n",
      "   ---------------------------- ----------- 32.5/45.8 MB 6.3 MB/s eta 0:00:03\n",
      "   ---------------------------- ----------- 32.7/45.8 MB 6.2 MB/s eta 0:00:03\n",
      "   ---------------------------- ----------- 32.9/45.8 MB 6.2 MB/s eta 0:00:03\n",
      "   ---------------------------- ----------- 33.1/45.8 MB 6.1 MB/s eta 0:00:03\n",
      "   ----------------------------- ---------- 33.4/45.8 MB 6.1 MB/s eta 0:00:03\n",
      "   ----------------------------- ---------- 33.6/45.8 MB 6.1 MB/s eta 0:00:03\n",
      "   ----------------------------- ---------- 33.9/45.8 MB 6.0 MB/s eta 0:00:02\n",
      "   ----------------------------- ---------- 34.1/45.8 MB 6.0 MB/s eta 0:00:02\n",
      "   ------------------------------ --------- 34.4/45.8 MB 6.0 MB/s eta 0:00:02\n",
      "   ------------------------------ --------- 34.6/45.8 MB 5.9 MB/s eta 0:00:02\n",
      "   ------------------------------ --------- 34.9/45.8 MB 5.8 MB/s eta 0:00:02\n",
      "   ------------------------------ --------- 35.1/45.8 MB 5.8 MB/s eta 0:00:02\n",
      "   ------------------------------ --------- 35.4/45.8 MB 5.8 MB/s eta 0:00:02\n",
      "   ------------------------------- -------- 35.6/45.8 MB 5.8 MB/s eta 0:00:02\n",
      "   ------------------------------- -------- 35.9/45.8 MB 5.7 MB/s eta 0:00:02\n",
      "   ------------------------------- -------- 36.1/45.8 MB 5.8 MB/s eta 0:00:02\n",
      "   ------------------------------- -------- 36.4/45.8 MB 5.8 MB/s eta 0:00:02\n",
      "   -------------------------------- ------- 36.7/45.8 MB 5.7 MB/s eta 0:00:02\n",
      "   -------------------------------- ------- 36.9/45.8 MB 5.7 MB/s eta 0:00:02\n",
      "   -------------------------------- ------- 37.2/45.8 MB 5.6 MB/s eta 0:00:02\n",
      "   -------------------------------- ------- 37.5/45.8 MB 5.7 MB/s eta 0:00:02\n",
      "   -------------------------------- ------- 37.7/45.8 MB 5.6 MB/s eta 0:00:02\n",
      "   --------------------------------- ------ 38.0/45.8 MB 5.6 MB/s eta 0:00:02\n",
      "   --------------------------------- ------ 38.3/45.8 MB 5.6 MB/s eta 0:00:02\n",
      "   --------------------------------- ------ 38.5/45.8 MB 5.6 MB/s eta 0:00:02\n",
      "   --------------------------------- ------ 38.8/45.8 MB 5.6 MB/s eta 0:00:02\n",
      "   ---------------------------------- ----- 39.1/45.8 MB 5.6 MB/s eta 0:00:02\n",
      "   ---------------------------------- ----- 39.4/45.8 MB 5.5 MB/s eta 0:00:02\n",
      "   ---------------------------------- ----- 39.7/45.8 MB 5.5 MB/s eta 0:00:02\n",
      "   ---------------------------------- ----- 39.9/45.8 MB 5.5 MB/s eta 0:00:02\n",
      "   ----------------------------------- ---- 40.2/45.8 MB 5.5 MB/s eta 0:00:02\n",
      "   ----------------------------------- ---- 40.5/45.8 MB 5.5 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 40.8/45.8 MB 5.7 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 41.1/45.8 MB 5.6 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 41.3/45.8 MB 5.5 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 41.7/45.8 MB 5.6 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 41.9/45.8 MB 5.6 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 42.3/45.8 MB 5.7 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 42.5/45.8 MB 5.7 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 42.9/45.8 MB 5.8 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 43.1/45.8 MB 5.8 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 43.4/45.8 MB 5.9 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 43.7/45.8 MB 5.8 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 44.0/45.8 MB 5.9 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 44.3/45.8 MB 5.9 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 44.6/45.8 MB 6.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------  44.9/45.8 MB 6.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------  45.2/45.8 MB 6.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------  45.4/45.8 MB 6.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------  45.7/45.8 MB 6.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------  45.8/45.8 MB 6.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------  45.8/45.8 MB 6.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 45.8/45.8 MB 5.7 MB/s eta 0:00:00\n",
      "Downloading threadpoolctl-3.2.0-py3-none-any.whl (15 kB)\n",
      "Installing collected packages: threadpoolctl, scipy, joblib, scikit-learn\n",
      "Successfully installed joblib-1.3.2 scikit-learn-1.4.0 scipy-1.12.0 threadpoolctl-3.2.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.2.1 -> 23.3.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "! pip install -U scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn\n",
    "import math\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "\n",
    "from sklearn.naive_bayes import GaussianNB, MultinomialNB, BernoulliNB\n",
    "from sklearn.metrics import classification_report, accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Обработка датасета"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Считывание csv-файлов\n",
    "train = pd.read_csv('train.csv')\n",
    "test = pd.read_csv('test.csv')\n",
    "gender_submission = pd.read_csv('gender_submission.csv')\n",
    "\n",
    "# Объеденение датасетов\n",
    "test_merge = pd.merge(test, gender_submission, how='left', on='PassengerId')\n",
    "df = pd.concat([test_merge, train], ignore_index=True)\n",
    "\n",
    "# Обработка Pclass\n",
    "df['Pclass'] = df['Pclass'].apply(lambda x: 3 - x + 1)\n",
    "\n",
    "# Обработка Sex\n",
    "df['sex_rank'] = df['Sex'].apply(lambda x: 0 if x == 'male' else 1)\n",
    "\n",
    "# Обработка Cabin\n",
    "df['Cabin_class'] = df['Cabin'].apply(lambda x: np.nan if type(x) != str and np.isnan(x) else x[0])\n",
    "df.iloc[[479, 1247], 10] = 'S'\n",
    "\n",
    "# Обработка Embarked\n",
    "df['embarked_s'] = df['Embarked'].apply(lambda x: 1 if x == 'S' else 0)\n",
    "df['embarked_c'] = df['Embarked'].apply(lambda x: 1 if x == 'C' else 0)\n",
    "df['embarked_q'] = df['Embarked'].apply(lambda x: 1 if x == 'Q' else 0)\n",
    "\n",
    "# Итоговый датасет\n",
    "df = df[['Pclass', 'sex_rank', 'Age', 'SibSp', 'Parch', 'Fare', 'embarked_s', 'embarked_c', 'embarked_q', 'Survived']]\n",
    "\n",
    "# Обработка пропусков в Age и Fare \n",
    "age_median = df['Age'].median()\n",
    "df['Age'] = df['Age'].apply(lambda x: age_median if np.isnan(x) else x)\n",
    "\n",
    "# Удаление дублей\n",
    "df.drop_duplicates(inplace=True, ignore_index=True)\n",
    "df.iloc[145, 5] = df[df['Pclass'] == 1]['Fare'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Краткий гайд по методу"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Данная модель обучается методом подсчета вероятности каждого признака по формуле Байеса, при условии, что каждый признак **независим**!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src='images/slide-26.jpg', with=250, height=250>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%html\n",
    "<img src='images/slide-26.jpg', with=250, height=250>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Пример расчета** "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://www.youtube.com/watch?v=5x1EQ7Bpb5Q&list=LL&index=14&t=1s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Практический пример для нашего случая"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Разберем подсчет вероятности к тому или иному классу, на примере одного столбца нашего датасета. Подсчитаем вероятность для события, что пассажир выживет, при условии, что он едет в 3 классе"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Survived</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1095</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1096</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1097</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1098</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1099</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1100 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Pclass  Survived\n",
       "0          1         0\n",
       "1          1         1\n",
       "2          2         0\n",
       "3          1         0\n",
       "4          1         1\n",
       "...      ...       ...\n",
       "1095       1         0\n",
       "1096       3         1\n",
       "1097       1         0\n",
       "1098       3         1\n",
       "1099       1         0\n",
       "\n",
       "[1100 rows x 2 columns]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# One feature dataset\n",
    "ofd = df[['Pclass', 'Survived']]\n",
    "ofd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**A** - Пассажир выжил(событие)\n",
    "\n",
    "**B** - Класс пассажира равен **3** (событие)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**P(A)** - Вероятность того, что пассажир выжил\n",
    "\n",
    "**P(B)** - Вероятность того, что класс пассажира = 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**P(A|B)** - Вероятность того, что пассажир выжил, при условии что он ехал в 3 классе(Событие B произошло)\n",
    "\n",
    "**P(B|A)** - Вероятность того, что пассажир ехал в 3 классе и выжил"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_A = len(ofd[ofd['Survived']==1])/len(ofd) # кол-во выжившых/кол-во всего\n",
    "\n",
    "p_B = len(ofd[ofd['Pclass']==3])/len(ofd) # кол-во пассажиров 1 класса / кол-во всех пассажиров всех классов\n",
    "\n",
    "p_BA = len(ofd[(ofd['Pclass']==3) & (ofd['Survived']==1)])/len(ofd[ofd['Pclass']==3]) # Кол-во выжившых пассажиров в классе 1/Кол-во пассажиров класса 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8627702360397432"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p_AB = (p_A * p_BA) / p_B\n",
    "p_AB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Соответственно, для того чтобы отнести к тому или иному классу, нам нужно посчитать вероятность принадлежности ко всем этим классам (в нашем случае: выжил-1, погиб-0). Относим запись к тому классу, у которого **наибольшая** вероятность.\n",
    "\n",
    "В случае, если имеется несколько признаков, сначала суммируем полученные вероятности посчитанные для каждого признака, а после классифицируем объект (по наибольшей сумме вероятностей)\n",
    "\n",
    "Такой подход работает в случае, если мы считаем что признаки независимы (**наивный Байес**)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Наивный Байес для непрерывных переменных (**Гаусовский**)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для подсчета вероятностей для признаков, которые имеются в качестве ннепрерывных переменных, считаем вероятность с использованием мат. ожидания(среднего) и дисперсии, по следующей формуле:\n",
    "\n",
    "![fewf](images/ГаусовскийБК.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В случае если у нас несколько таких столбцов можно воспользоваться формулой (чтобы не усреднять):\n",
    "\n",
    "![fewf](images/ГаусовскийБК_для_нескольких_переменных.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Важно**\n",
    "Этот будет работать плохо, если значения признаков **не подчиняются** Гаусовскому закону распределения"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive Bayess in Sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(df.iloc[:, :-1], df.iloc[:, -1], train_size=0.80,\n",
    "                                                    test_size=0.20, stratify=df.iloc[:, -1], random_state=123)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### GaussianNB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Представляет собой классификатор, основанный на предположении, что вероятность наличия признаков равна гауссовскому распределению"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7681818181818182"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gnb = GaussianNB()\n",
    "gnb.fit(X_train, y_train)\n",
    "\n",
    "y_pred = gnb.predict(X_test)\n",
    "\n",
    "sklearn.metrics.accuracy_score(y_pred, y_test)\n",
    "#.score(y_pred, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### MultinomialNB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Он представляет собой классификатор, подходящий для многомерно распределенных данных.\n",
    "Он хорошо подходит для задач классификации текста."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7227272727272728"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnb = MultinomialNB()\n",
    "mnb.fit(X_train, y_train)\n",
    "\n",
    "y_pred = mnb.predict(X_test)\n",
    "\n",
    "sklearn.metrics.accuracy_score(y_pred, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### BernoulliNB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Он представляет собой классификатор, основанный на данных, представляющих собой многомерные распределения Бернулли.\n",
    "Распределение Бернулли подразумевает, что данные могут иметь множество характеристик, но предполагается, что каждая из них является двоичной переменной."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8136363636363636"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bnb = BernoulliNB()\n",
    "bnb.fit(X_train, y_train)\n",
    "\n",
    "y_pred = bnb.predict(X_test)\n",
    "\n",
    "sklearn.metrics.accuracy_score(y_pred, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Усредненный accuracy используя все типы классификаторов (GaussianNB, MultinomialNB, BernoulliNB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.20454545454545456"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Считаем вероятности для всех типов переменных (непрерывные, категориальные, бинарные)\n",
    "gnb1 = GaussianNB()\n",
    "gnb1.fit(X_train[['Age', 'Fare']], y_train)\n",
    "y_pred_gnb1 = gnb1.predict_proba(X_test[['Age', 'Fare']])\n",
    "y_pred_gnb1\n",
    "\n",
    "mnb1 = MultinomialNB()\n",
    "mnb1.fit(X_train[['Pclass', 'SibSp', 'Parch']], y_train)\n",
    "y_pred_mnb1 = mnb1.predict_proba(X_test[['Pclass', 'SibSp', 'Parch']])\n",
    "y_pred_mnb1\n",
    "\n",
    "bnb1 = BernoulliNB()\n",
    "bnb1.fit(X_train[['sex_rank', 'embarked_s', 'embarked_c', 'embarked_q']], y_train)\n",
    "y_pred_bnb1 = bnb1.predict_proba(X_test[['sex_rank', 'embarked_s', 'embarked_c', 'embarked_q']])\n",
    "y_pred_bnb1\n",
    "\n",
    "# Усредняем полученные результаты\n",
    "arr = np.array([])\n",
    "for i in range(len(y_pred_bnb1)):\n",
    "    probability_true = (y_pred_gnb1[i][0] + y_pred_mnb1[i][0] + y_pred_bnb1[i][0])/3\n",
    "    probability_false = (y_pred_gnb1[i][1] + y_pred_mnb1[i][1] + y_pred_bnb1[i][1])/3\n",
    "\n",
    "    arr = np.append(arr, 1 if probability_true>probability_false else 0)\n",
    "\n",
    "\n",
    "sklearn.metrics.accuracy_score(arr, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Свой наивный Баейсовский классификатор Гауса, для бинарной классификации"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(df.iloc[:, :-1], df.iloc[:, -1], train_size=0.80,\n",
    "                                                    test_size=0.20, stratify=df.iloc[:, -1], random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(df.iloc[:, 0:-1], df.iloc[:, -1], train_size=0.8, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class СlassificationNB:\n",
    "    def fit(self, x_train, y_train, category_columns:list=None, continuous_columns:list=None):\n",
    "        self.count_feture_survived = {}\n",
    "        self.count_feture_dead = {}\n",
    "\n",
    "        for i in x_train.columns:\n",
    "            survived_df, dead_df = x_train[y_train==1][i], x_train[y_train==0][i]\n",
    "            m_survived, m_dead = survived_df.mean(), dead_df.mean()\n",
    "            p_survived, p_dead = len(y_train[y_train==1])/len(y_train), len(y_train[y_train==0])/len(y_train)\n",
    "\n",
    "            dispersion_survived = survived_df.apply(lambda x: (x-m_survived)**2).sum()/len(survived_df-1)\n",
    "            dispersion_dead = dead_df.apply(lambda x: (x-m_dead)**2).sum()/len(dead_df-1)\n",
    "\n",
    "            self.count_feture_survived[i] = [p_survived, m_survived, dispersion_survived]\n",
    "            self.count_feture_dead[i] = [p_dead, m_dead, dispersion_dead]\n",
    "\n",
    "        return (self.count_feture_survived, self.count_feture_dead)\n",
    "\n",
    "\n",
    "    def predict(self, x_test):\n",
    "\n",
    "        x_test = x_test.reset_index().iloc[:, 1:]\n",
    "\n",
    "        total_prob_survived_df = pd.DataFrame({'surv': [0]*len(x_test)})\n",
    "        total_prob_dead_df = pd.DataFrame({'dead': [0]*len(x_test)})\n",
    "\n",
    "        for i in x_test.columns:\n",
    "\n",
    "            total_prob_survived_df = pd.concat([total_prob_survived_df,\n",
    "                x_test[i].apply(lambda x: math.log(self.count_feture_survived[i][0]) + (-((x-self.count_feture_survived[i][1])**2/(2*self.count_feture_survived[i][2]**2))))\n",
    "                ], axis=1).sum(axis=1)\n",
    "\n",
    "            total_prob_dead_df = pd.concat([total_prob_dead_df,\n",
    "                x_test[i].apply(lambda x: math.log(self.count_feture_dead[i][0]) + (-((x-self.count_feture_dead[i][1])**2/(2*self.count_feture_dead[i][2]**2))))\n",
    "                ], axis=1).sum(axis=1)\n",
    "\n",
    "        print(total_prob_survived_df, total_prob_dead_df)\n",
    "\n",
    "        return (total_prob_survived_df > total_prob_dead_df.values).map(lambda x: int(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'Pclass': [0.425, 2.0240641711229945, 0.7668005948125481],\n",
       "  'sex_rank': [0.425, 0.7620320855614974, 0.18133918613629216],\n",
       "  'Age': [0.425, 28.89596256684492, 208.96423797720837],\n",
       "  'SibSp': [0.425, 0.5053475935828877, 0.5654794246332465],\n",
       "  'Parch': [0.425, 0.5481283422459893, 0.8840472990362893],\n",
       "  'Fare': [0.425, 49.99249144385027, 4639.73812686688],\n",
       "  'embarked_s': [0.425, 0.6443850267379679, 0.22915296405387625],\n",
       "  'embarked_c': [0.425, 0.2887700534759358, 0.20538190969144096],\n",
       "  'embarked_q': [0.425, 0.06684491978609626, 0.0623766764848866]},\n",
       " {'Pclass': [0.575, 1.5849802371541502, 0.6261775687793905],\n",
       "  'sex_rank': [0.575, 0.11857707509881422, 0.10451655235982439],\n",
       "  'Age': [0.575, 30.38717391304348, 185.6875673096752],\n",
       "  'SibSp': [0.575, 0.5237154150197628, 1.111097658141824],\n",
       "  'Parch': [0.575, 0.391304347826087, 0.9180271524316892],\n",
       "  'Fare': [0.575, 26.23407867660798, 1355.5376934950268],\n",
       "  'embarked_s': [0.575, 0.7351778656126482, 0.19469137152587915],\n",
       "  'embarked_c': [0.575, 0.18774703557312253, 0.1524980862066272],\n",
       "  'embarked_q': [0.575, 0.07707509881422925, 0.07113452795700605]})"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_nbc = СlassificationNB()\n",
    "my_nbc.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0      -20.470958\n",
      "1      -20.781695\n",
      "2      -12.796859\n",
      "3      -20.780570\n",
      "4      -20.764496\n",
      "          ...    \n",
      "215    -19.890614\n",
      "216    -16.453426\n",
      "217    -22.983195\n",
      "218   -134.856837\n",
      "219    -13.078595\n",
      "Length: 220, dtype: float64 0     -65.179040\n",
      "1      -8.534264\n",
      "2     -43.431478\n",
      "3      -8.532410\n",
      "4      -8.513647\n",
      "         ...    \n",
      "215    -8.318395\n",
      "216   -47.381173\n",
      "217    -9.087807\n",
      "218   -98.316835\n",
      "219   -44.679317\n",
      "Length: 220, dtype: float64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0      1\n",
       "1      0\n",
       "2      1\n",
       "3      0\n",
       "4      0\n",
       "      ..\n",
       "215    0\n",
       "216    1\n",
       "217    0\n",
       "218    0\n",
       "219    1\n",
       "Length: 220, dtype: int64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = my_nbc.predict(x_test)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8045454545454546"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sklearn.metrics.accuracy_score(y_pred, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Видим достаточно хороший score близкий к результату sklearn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Полезные ссылки для этого классификатора"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Нелохие статьи для лучшего понимания**\n",
    "- https://dzen.ru/a/YlrgU9faUy9WDu1l\n",
    "- https://www.guru99.com/ru/naive-bayes-classifiers.html\n",
    "- https://datascience.stackexchange.com/questions/27624/difference-between-bernoulli-and-multinomial-naive-bayes\n",
    "- https://coderzcolumn.com/tutorials/machine-learning/scikit-learn-sklearn-naive-bayes\n",
    "- https://datareview.info/article/6-prostyih-shagov-dlya-osvoeniya-naivnogo-bayesovskogo-algoritma-s-primerom-koda-na-python/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Полезные ответы на stackoverflow**\n",
    "- https://stackoverflow.com/questions/14254203/mixing-categorial-and-continuous-data-in-naive-bayes-classifier-using-scikit-lea\n",
    "- https://stackoverflow.com/questions/38621053/how-can-i-use-sklearn-naive-bayes-with-multiple-categorical-features"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
